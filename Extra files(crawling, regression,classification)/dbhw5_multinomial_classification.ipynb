{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris 데이터 및 scikit learn logistic regression을 이용하여\n",
    "\n",
    "붓꽃의 3가지 종류를 구분하는 multinomial classification을 구현할 것.\n",
    "\n",
    " \n",
    "\n",
    "- one-vs-all, one-vs-one 두가지 방법을 사용할 것.\n",
    "\n",
    "- performance measure는 accuracy를 사용할 것.\n",
    "\n",
    "- one-vs-one을 구현할때, 데이터에서 두개의 클래스에서 해당되지 않는 레이블의 데이터는 필터링해서 하여야 함.\n",
    "\n",
    "- training/test 데이터를 7:3으로 split 하는 방법과 k-fold 방식으로 성능평가하는 방식. 두가지를 해볼 것.\n",
    "\n",
    "- 데이터를 split할 때, 한쪽으로 데이터의 레이블이 쏠리지 않도록 shuffle 할것.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-vs-one\n",
    "\n",
    "def kfold(X,y,idx):\n",
    "    \n",
    "    global checklabel\n",
    "    X,y,idx=shuffle(X,y,idx)\n",
    "    result=0\n",
    "    \n",
    "    KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        idx_transfered=idx[test_index]\n",
    "\n",
    "        lr_model = LogisticRegression(random_state=None, solver='liblinear',multi_class='ovr')\n",
    "        lr_model.fit(X_train,y_train)\n",
    "        coef=lr_model.coef_\n",
    "        print(lr_model.coef_,lr_model.intercept_) #가중치,상수\n",
    "\n",
    "        y_test_pred = lr_model.predict(X_test)\n",
    "        for j in range(len(y_test_pred)):\n",
    "            temp=0\n",
    "            if y_test_pred[j]==\"versicolor\":\n",
    "                temp=1\n",
    "            elif y_test_pred[j]==\"virginica\":\n",
    "                temp=2\n",
    "            checklabel[idx_transfered[j][0]][temp]+=1\n",
    "                \n",
    "        temp=accuracy_score(y_test,y_test_pred)\n",
    "        print(\"accuracy for each kfold : \", temp)\n",
    "        result+=temp\n",
    "    \n",
    "    print(\"\\naccuracy for one class : \",result/5,\"\\n\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35788387 -1.42827745  2.11778591  0.91931326]] [-0.23994223]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.39167751 -1.37796341  2.13291582  0.96349893]] [-0.25390818]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.39174825 -1.38953323  2.13187036  0.95606276]] [-0.26260154]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.38440996 -1.3816851   2.12237857  0.96636637]] [-0.24255576]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.38133985 -1.37942536  2.12918813  0.92584223]] [-0.23295738]\n",
      "accuracy for each kfold :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[-0.54170053 -1.08568302  1.77298031  0.90310066]] [-0.29010974]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.51380246 -1.13460528  1.73306736  0.92857349]] [-0.27140644]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.53746208 -1.11606751  1.73025413  0.88651884]] [-0.29578337]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.53896718 -1.11421245  1.75797687  0.90419154]] [-0.28574919]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-0.52301452 -1.09479755  1.73635579  0.8884224 ]] [-0.27988294]\n",
      "accuracy for each kfold :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[-1.49954665 -1.5624971   2.31285609  2.17752717]] [-1.007583]\n",
      "accuracy for each kfold :  0.95\n",
      "[[-1.6419035  -1.49349285  2.4289867   2.24846089]] [-1.00563083]\n",
      "accuracy for each kfold :  0.95\n",
      "[[-1.59928484 -1.28817847  2.30010173  2.21996671]] [-1.11412925]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-1.53247503 -1.43548844  2.21042256  2.36176115]] [-1.15986661]\n",
      "accuracy for each kfold :  1.0\n",
      "[[-1.64172854 -1.19114029  2.16184321  2.57084882]] [-1.05903318]\n",
      "accuracy for each kfold :  0.95\n",
      "\n",
      "accuracy for one class :  0.97 \n",
      "\n",
      "\n",
      "one-vs-one accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import operator\n",
    "\n",
    "file='/Users/Desktop/iris.csv'\n",
    "data=pd.read_csv(file)\n",
    "\n",
    "checklabel=[[int(0)]*3 for i in range(150)]\n",
    "\n",
    "\n",
    "type1=np.array(data.iloc[:50,0:4])\n",
    "label1=np.array(data.iloc[:50,4])\n",
    "type2=np.array(data.iloc[50:100,0:4])\n",
    "label2=np.array(data.iloc[50:100,4])\n",
    "type3=np.array(data.iloc[100:150,0:4])\n",
    "label3=np.array(data.iloc[100:150,4])\n",
    "\n",
    "idx1=[[i] for i in range(50)]\n",
    "idx2=[[i] for i in range(50,100)]\n",
    "idx3=[[i] for i in range(100,150)]\n",
    "\n",
    "X=np.concatenate((type1,type2),axis=0)\n",
    "y=np.concatenate((label1,label2),axis=0)\n",
    "kfold(X,y,np.concatenate((idx1,idx2),axis=0))\n",
    "\n",
    "X=np.concatenate((type1,type3),axis=0)\n",
    "y=np.concatenate((label1,label3),axis=0)\n",
    "kfold(X,y,np.concatenate((idx1,idx3),axis=0))\n",
    "    \n",
    "X=np.concatenate((type2,type3),axis=0)\n",
    "y=np.concatenate((label2,label3),axis=0)\n",
    "kfold(X,y,np.concatenate((idx2,idx3),axis=0))\n",
    "\n",
    "resultidx=[]\n",
    "for i in checklabel:\n",
    "    temp, value = max(enumerate(i), key=operator.itemgetter(1))\n",
    "    if str(temp)==\"0\":\n",
    "        resultidx.append(\"setosa\")\n",
    "    elif str(temp)==\"1\":\n",
    "        resultidx.append(\"versicolor\")\n",
    "    else:\n",
    "        resultidx.append(\"virginica\")\n",
    "\n",
    "temp=accuracy_score(resultidx,data.iloc[:,4])\n",
    "print(\"one-vs-one accuracy : \", temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-vs-one\n",
    "\n",
    "def split(X,y,idx):\n",
    "    result=0\n",
    "    for trial in range(5):\n",
    "        global checklabel\n",
    "        X,y,idx=shuffle(X,y,idx)\n",
    "\n",
    "        X_train, X_test, y_train, y_test, idx_temp, idx_transfered = train_test_split(X, y,idx, test_size=0.3, random_state=42)\n",
    "\n",
    "        lr_model = LogisticRegression(random_state=None, solver='liblinear',multi_class='ovr')\n",
    "        lr_model.fit(X_train,y_train)\n",
    "        coef=lr_model.coef_\n",
    "        print(lr_model.coef_,lr_model.intercept_) #가중치,상수\n",
    "\n",
    "        y_test_pred = lr_model.predict(X_test)\n",
    "        for j in range(len(y_test_pred)):\n",
    "            temp=0\n",
    "            if y_test_pred[j]==\"versicolor\":\n",
    "                 temp=1\n",
    "            elif y_test_pred[j]==\"virginica\":\n",
    "                 temp=2\n",
    "            checklabel[idx_transfered[j][0]][temp]+=1\n",
    "    \n",
    "        temp=accuracy_score(y_test,y_test_pred)\n",
    "        print(\"accuracy for each trial : \", temp)\n",
    "        result+=temp\n",
    "    \n",
    "    print(\"\\naccuracy for one class : \",result/5,\"\\n\\n\")\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3903948  -1.36368755  2.0614069   0.90103182]] [-0.24083145]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.36212407 -1.3563174   2.07440213  0.92512505]] [-0.24282948]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.36193519 -1.34842892  2.0772765   0.91426932]] [-0.23015344]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.33916736 -1.31992913  2.06190718  0.89462786]] [-0.23674589]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.37262451 -1.3266087   2.0859366   0.91038419]] [-0.259211]\n",
      "accuracy for each trial :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[-0.51997378 -1.07407739  1.69657478  0.90271749]] [-0.27000796]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.52109152 -1.08105615  1.71655258  0.88160236]] [-0.2807216]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.53496455 -1.06938251  1.70156063  0.88743694]] [-0.28053818]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.50858176 -1.08541976  1.68074924  0.874315  ]] [-0.28045455]\n",
      "accuracy for each trial :  1.0\n",
      "[[-0.52641727 -1.05841579  1.71400928  0.85009734]] [-0.27980619]\n",
      "accuracy for each trial :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[-1.60284935 -1.39881969  2.46078173  1.82355868]] [-1.00614975]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "[[-1.44001546 -1.38769565  2.13724566  2.17897338]] [-1.03310278]\n",
      "accuracy for each trial :  1.0\n",
      "[[-1.72648312 -1.14556891  2.34759303  2.03755685]] [-0.92406437]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "[[-1.54566795 -1.06357555  2.12916903  2.13336112]] [-0.98854329]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "[[-1.56796133 -1.33203073  2.27983463  2.10284298]] [-0.93139533]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "\n",
      "accuracy for one class :  0.9733333333333334 \n",
      "\n",
      "\n",
      "one-vs-one accuracy :  0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "\n",
    "file='/Users/Desktop/iris.csv'\n",
    "data=pd.read_csv(file)\n",
    "\n",
    "checklabel=[[int(0)]*3 for i in range(150)]\n",
    "\n",
    "\n",
    "type1=np.array(data.iloc[:50,0:4])\n",
    "label1=np.array(data.iloc[:50,4])\n",
    "type2=np.array(data.iloc[50:100,0:4])\n",
    "label2=np.array(data.iloc[50:100,4])\n",
    "type3=np.array(data.iloc[100:150,0:4])\n",
    "label3=np.array(data.iloc[100:150,4])\n",
    "\n",
    "idx1=[[i] for i in range(50)]\n",
    "idx2=[[i] for i in range(50,100)]\n",
    "idx3=[[i] for i in range(100,150)]\n",
    "\n",
    "X=np.concatenate((type1,type2),axis=0)\n",
    "y=np.concatenate((label1,label2),axis=0)\n",
    "split(X,y,np.concatenate((idx1,idx2),axis=0))\n",
    "\n",
    "X=np.concatenate((type1,type3),axis=0)\n",
    "y=np.concatenate((label1,label3),axis=0)\n",
    "split(X,y,np.concatenate((idx1,idx3),axis=0))\n",
    "    \n",
    "X=np.concatenate((type2,type3),axis=0)\n",
    "y=np.concatenate((label2,label3),axis=0)\n",
    "split(X,y,np.concatenate((idx2,idx3),axis=0))\n",
    "\n",
    "\n",
    "resultidx=[]\n",
    "for i in checklabel:\n",
    "    temp, value = max(enumerate(i), key=operator.itemgetter(1))\n",
    "    if str(temp)==\"0\":\n",
    "        resultidx.append(\"setosa\")\n",
    "    elif str(temp)==\"1\":\n",
    "        resultidx.append(\"versicolor\")\n",
    "    else:\n",
    "        resultidx.append(\"virginica\")\n",
    "\n",
    "\n",
    "temp=accuracy_score(resultidx,data.iloc[:,4])\n",
    "print(\"one-vs-one accuracy : \", temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-vs-rest\n",
    "\n",
    "def kfold(X,y,idx, _class):\n",
    "    result=0\n",
    "    global checklabel\n",
    "    X,y,idx=shuffle(X,y,idx)\n",
    "\n",
    "    KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        idx_transfered=idx[test_index]\n",
    "\n",
    "        lr_model = LogisticRegression(random_state=None, solver='liblinear',multi_class='ovr')\n",
    "        lr_model.fit(X_train,y_train)\n",
    "        coef=lr_model.coef_\n",
    "        print(lr_model.coef_,lr_model.intercept_) #가중치,상수\n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            temp=coef*X_test[i]\n",
    "            temp_sum=[sum(j) for j in temp][0] + lr_model.intercept_\n",
    "            temp=1 / (1 + np.exp(-1*temp_sum))\n",
    "            checklabel[idx_transfered[i]][_class]+=temp[0]\n",
    "        \n",
    "        y_test_pred = lr_model.predict(X_test)\n",
    "        temp=accuracy_score(y_test,y_test_pred)\n",
    "        print(\"accuracy for each trial : \", temp)\n",
    "        result+=temp\n",
    "    \n",
    "    print(\"\\naccuracy for one class : \",result/5,\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38828874  1.39362524 -2.15982715 -0.99815336]] [0.25900842]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.41545845  1.36363506 -2.15814847 -0.9438865 ]] [0.27245649]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.37379746  1.41000138 -2.13438302 -0.94208647]] [0.24114688]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.39882549  1.38522982 -2.16946528 -0.99048565]] [0.2621625]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.37445601  1.40805798 -2.13880573 -0.97325501]] [0.22635373]\n",
      "accuracy for each trial :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[ 0.4921568  -1.62737192  0.43930187 -1.12405033]] [0.87314202]\n",
      "accuracy for each trial :  0.6\n",
      "[[ 0.41385701 -1.56656798  0.49228642 -1.17758135]] [1.04307683]\n",
      "accuracy for each trial :  0.7\n",
      "[[ 0.4133476  -1.48147096  0.46564026 -1.08761192]] [0.85001479]\n",
      "accuracy for each trial :  0.7333333333333333\n",
      "[[ 0.45008479 -1.55949391  0.65303097 -1.55835497]] [0.78693698]\n",
      "accuracy for each trial :  0.7\n",
      "[[ 0.27800494 -1.33529842  0.61651419 -1.38977136]] [0.95431394]\n",
      "accuracy for each trial :  0.6666666666666666\n",
      "\n",
      "accuracy for one class :  0.6799999999999999 \n",
      "\n",
      "\n",
      "[[-1.47414425 -1.47519062  2.16706764  2.3540554 ]] [-1.03067278]\n",
      "accuracy for each trial :  1.0\n",
      "[[-1.48405955 -1.39943228  2.20969598  2.20210328]] [-1.13568993]\n",
      "accuracy for each trial :  1.0\n",
      "[[-1.58461626 -1.59222951  2.41982519  2.26898273]] [-1.10619523]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "[[-1.76948828 -0.99031427  2.17684666  2.57903218]] [-0.94971572]\n",
      "accuracy for each trial :  0.9333333333333333\n",
      "[[-1.62357663 -1.50953148  2.44992099  2.20779166]] [-1.10524511]\n",
      "accuracy for each trial :  0.9666666666666667\n",
      "\n",
      "accuracy for one class :  0.9733333333333334 \n",
      "\n",
      "\n",
      "one-vs-rest accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "\n",
    "file='/Users/Desktop/iris.csv'\n",
    "data=pd.read_csv(file)\n",
    "\n",
    "checklabel=[[int(0)]*3 for i in range(150)]\n",
    "\n",
    "label1=np.array(data.iloc[:50,4])\n",
    "label2=np.array(data.iloc[50:100,4])\n",
    "label3=np.array(data.iloc[100:150,4])\n",
    "\n",
    "temp=['other' for i in range(50)]\n",
    "X=np.array(data.iloc[:,0:4])\n",
    "idx=np.array([i for i in range(150)])\n",
    "\n",
    "y=np.concatenate((label1,temp),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "kfold(X,y,idx,0)\n",
    "\n",
    "y=np.concatenate((temp,label2),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "kfold(X,y,idx,1)\n",
    "\n",
    "y=np.concatenate((temp,temp),axis=0)\n",
    "y=np.concatenate((y,label3),axis=0)\n",
    "kfold(X,y,idx,2)\n",
    "\n",
    "\n",
    "\n",
    "resultidx=[]\n",
    "for i in checklabel:\n",
    "    temp, value = max(enumerate(i), key=operator.itemgetter(1))\n",
    "    if str(temp)==\"0\":\n",
    "        resultidx.append(\"setosa\")\n",
    "    elif str(temp)==\"1\":\n",
    "        resultidx.append(\"versicolor\")\n",
    "    else:\n",
    "        resultidx.append(\"virginica\")\n",
    "\n",
    "\n",
    "temp=accuracy_score(resultidx,data.iloc[:,4])\n",
    "print(\"one-vs-rest accuracy : \", temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.concatenate((label1,temp),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "kfold(X,y,idx,0)\n",
    "\n",
    "y=np.concatenate((temp,label2),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "kfold(X,y,idx,1)\n",
    "\n",
    "y=np.concatenate((temp,temp),axis=0)\n",
    "y=np.concatenate((y,label3),axis=0)\n",
    "kfold(X,y,idx,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-vs-rest\n",
    "\n",
    "def split(X,y,idx, _class):\n",
    "    result=0\n",
    "    for trial in range(5):\n",
    "        global checklabel\n",
    "        X,y,idx=shuffle(X,y,idx)\n",
    "\n",
    "        X_train, X_test, y_train, y_test, idx_temp, idx_transfered = train_test_split(X, y,idx, test_size=0.3, random_state=42)\n",
    "\n",
    "        lr_model = LogisticRegression(random_state=None, solver='liblinear',multi_class='ovr')\n",
    "        lr_model.fit(X_train,y_train)\n",
    "        coef=lr_model.coef_\n",
    "        print(lr_model.coef_,lr_model.intercept_) #가중치,상수\n",
    "        \n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            temp=coef*X_test[i]\n",
    "            temp_sum=[sum(j) for j in temp][0] + lr_model.intercept_\n",
    "            temp=1 / (1 + np.exp(-1*temp_sum))\n",
    "            checklabel[idx_transfered[i]][_class]+=temp[0]\n",
    "        \n",
    "        y_test_pred = lr_model.predict(X_test)\n",
    "        temp=accuracy_score(y_test,y_test_pred)\n",
    "        print(\"accuracy for each trial : \", temp)\n",
    "        result+=temp\n",
    "    \n",
    "    print(\"\\naccuracy for one class : \",result/5,\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.39040984  1.31863539 -2.10018047 -1.00742837]] [0.26907204]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.41724319  1.31227756 -2.10294705 -0.89687967]] [0.25488071]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.39222551  1.33211087 -2.10540691 -0.92206721]] [0.24095329]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.39441051  1.29378653 -2.08259323 -0.93610133]] [0.27043254]\n",
      "accuracy for each trial :  1.0\n",
      "[[ 0.3814485   1.31998544 -2.07987814 -0.92587839]] [0.23372492]\n",
      "accuracy for each trial :  1.0\n",
      "\n",
      "accuracy for one class :  1.0 \n",
      "\n",
      "\n",
      "[[ 0.45372857 -1.62745299  0.6177927  -1.49236794]] [0.93972541]\n",
      "accuracy for each trial :  0.6666666666666666\n",
      "[[ 0.62732372 -1.83465175  0.38091822 -1.15251286]] [0.81967802]\n",
      "accuracy for each trial :  0.5777777777777777\n",
      "[[ 0.33676401 -1.36433687  0.34696146 -0.80085144]] [0.98249772]\n",
      "accuracy for each trial :  0.6666666666666666\n",
      "[[ 0.38795468 -1.49695531  0.69919215 -1.51605022]] [0.78097167]\n",
      "accuracy for each trial :  0.6888888888888889\n",
      "[[ 0.29485527 -1.36787278  0.58121914 -1.16941028]] [0.80931021]\n",
      "accuracy for each trial :  0.6\n",
      "\n",
      "accuracy for one class :  0.6399999999999999 \n",
      "\n",
      "\n",
      "[[-1.67866735 -0.8757901   1.95864163  2.6536489 ]] [-0.90690084]\n",
      "accuracy for each trial :  0.9555555555555556\n",
      "[[-1.60534414 -1.28826971  2.32077246  2.12298362]] [-0.92055367]\n",
      "accuracy for each trial :  0.9555555555555556\n",
      "[[-1.33209925 -1.46007468  2.05742946  2.0716488 ]] [-0.89438377]\n",
      "accuracy for each trial :  0.9777777777777777\n",
      "[[-1.54225014 -1.29946389  2.21427046  2.14752944]] [-1.01390465]\n",
      "accuracy for each trial :  1.0\n",
      "[[-1.43687063 -1.40779239  2.06382649  2.28338085]] [-0.89204121]\n",
      "accuracy for each trial :  0.9777777777777777\n",
      "\n",
      "accuracy for one class :  0.9733333333333333 \n",
      "\n",
      "\n",
      "one-vs-rest accuracy :  0.74\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "\n",
    
    "file='/Users/Desktop/iris.csv'\n",
    "data=pd.read_csv(file)\n",
    "\n",
    "checklabel=[[int(0)]*3 for i in range(150)]\n",
    "\n",
    "label1=np.array(data.iloc[:50,4])\n",
    "label2=np.array(data.iloc[50:100,4])\n",
    "label3=np.array(data.iloc[100:150,4])\n",
    "\n",
    "temp=['other' for i in range(50)]\n",
    "X=np.array(data.iloc[:,0:4])\n",
    "idx=[i for i in range(150)]\n",
    "\n",
    "y=np.concatenate((label1,temp),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "split(X,y,idx,0)\n",
    "\n",
    "y=np.concatenate((temp,label2),axis=0)\n",
    "y=np.concatenate((y,temp),axis=0)\n",
    "split(X,y,idx,1)\n",
    "\n",
    "y=np.concatenate((temp,temp),axis=0)\n",
    "y=np.concatenate((y,label3),axis=0)\n",
    "split(X,y,idx,2)\n",
    "\n",
    "resultidx=[]\n",
    "for i in checklabel:\n",
    "    temp, value = max(enumerate(i), key=operator.itemgetter(1))\n",
    "    if str(temp)==\"0\":\n",
    "        resultidx.append(\"setosa\")\n",
    "    elif str(temp)==\"1\":\n",
    "        resultidx.append(\"versicolor\")\n",
    "    else:\n",
    "        resultidx.append(\"virginica\")\n",
    "\n",
    "\n",
    "temp=accuracy_score(resultidx,data.iloc[:,4])\n",
    "print(\"one-vs-rest accuracy : \", temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
